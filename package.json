{
  "name": "llm-inject-scan",
  "version": "0.1.1",
  "main": "dist/index.ts",
  "module": "dist/index.mjs",
  "types": "dist/index.d.ts",
  "exports": {
    ".": {
      "require": "./dist/index.js",
      "import": "./dist/index.mjs"
    }
  },
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "build": "tsup src/index.ts --format cjs,esm --dts --clean",
    "prepublishOnly": "npm run build"
  },
  "keywords": [
    "llm",
    "prompt-injection",
    "jailbreak-detection",
    "guardrails",
    "ai-guardrails",
    "ai-security",
    "prompt-security",
    "prompt-leak",
    "injection",
    "security",
    "openai",
    "anthropic",
    "gpt",
    "llm-injection"
  ],
  "author": "",
  "license": "ISC",
  "description": "",
  "devDependencies": {
    "@types/jest": "^30.0.0",
    "jest": "^29.7.0",
    "ts-jest": "^29.4.1",
    "typescript": "^5.9.2"
  },
  "files": [
    "dist",
    "README.md"
  ],
  "engines": {
    "node": ">=14"
  }
}
